{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guruprasad\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "# Matplotlib for additional customization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# build predictive model\n",
    "from tensorly.regression.kruskal_regression import KruskalRegressor\n",
    "import tensorly.backend as T\n",
    "from tensorly.decomposition import parafac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import .MAT files\n",
    "1. $File1:$ SharedData.mat (raw data)\n",
    "2. $File2:$ spikeData_1ms_rawSpikes.mat (spikeData binned and referenced according to sessionNum, trialNum and reach-direction)\n",
    "3. $File3:$ stateData_1ms_cursorState_organized.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['#refs#', 'SessionDay', 'sdata', 'state', 'target', 'trialTimes'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C://Users//Guruprasad//Desktop/OneDrive - California Institute of Technology/Human Neural data analysis/\"\n",
    "file_name = \"SharedData.mat\"\n",
    "arrays = {}\n",
    "\n",
    "g= h5py.File(data_path+file_name, 'r')\n",
    "for k, v in g.items():\n",
    "    arrays[k] = np.array(v)\n",
    "    \n",
    "arrays.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['#refs#', 'struct_rawSpikeData'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C://Users//Guruprasad//Desktop/OneDrive - California Institute of Technology/Human Neural data analysis/\"\n",
    "file_name = \"spikeData_1msbins_rawSpikes.mat\"\n",
    "\n",
    "arrays_spikes = {}\n",
    "\n",
    "f = h5py.File(data_path+file_name,'r') \n",
    "for k, v in f.items():\n",
    "    arrays_spikes[k] = np.array(v)\n",
    "    \n",
    "arrays_spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['#refs#', 'struct_state'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C://Users//Guruprasad//Desktop/OneDrive - California Institute of Technology/Human Neural data analysis/Playing with data/\"\n",
    "file_name = \"stateData_1msbins_cursorState_organized.mat\"\n",
    "arrays_cursorState = {}\n",
    "\n",
    "f_cursorState = h5py.File(data_path+file_name,'r') \n",
    "for k, v in f_cursorState.items():\n",
    "    arrays_cursorState[k] = np.array(v)\n",
    "    \n",
    "arrays_cursorState.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing the neural spiking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussKernel(windowSize,std_dev):\n",
    "    \n",
    "    gauss_kernel = np.zeros([windowSize]);\n",
    "    \n",
    "    win_center = (windowSize-1)/2;\n",
    "    for i in range(windowSize):\n",
    "        gauss_kernel[i] = math.exp(-math.pow((i-win_center),2)/(2*math.pow(std_dev,2)));\n",
    "    \n",
    "    #gauss_kernel = gauss_kernel/np.sum(gauss_kernel); #Normalization\n",
    "    return gauss_kernel    \n",
    "\n",
    "def gauss_smooth(a, gauss_kernel):\n",
    "    \n",
    "    a_smooth = deepcopy(a);\n",
    "    \n",
    "    for row in range(a.shape[0]):\n",
    "        for col in range(a.shape[1]-len(gauss_kernel)):\n",
    "            \n",
    "            a_smooth[row,int(col+(len(gauss_kernel)-1)/2)] = np.mean(a[row,col:col+len(gauss_kernel)]*gauss_kernel);\n",
    "    \n",
    "    return a_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for one session and one trial\n",
    "s_id = 0\n",
    "y_ref =arrays['target'][s_id,0]\n",
    "target_s = g[y_ref][()]\n",
    "n_trial_s = len(target_s)\n",
    "y = target_s.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Neuron-spikeData tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index:1 - Number of trials; Index:2 - Number of tasks; Index:3 - Number of sessions\n",
    "x_ref = arrays_spikes['struct_rawSpikeData']\n",
    "xstate_ref = arrays_cursorState['struct_state']\n",
    "\n",
    "# Make a 3-d matrix/tensor using all spikeData over multiple sessions and trials for a single task (reaching direction)\n",
    "\n",
    "neuron_tempTensor = np.zeros([96,3000,150]);\n",
    "target_states = np.zeros([3000,2]);\n",
    "\n",
    "task= 0; #[All 8 reaching directions referenced from 0:7]\n",
    "ctr = 0; # Keeping track of number of trials (in z-dimension)\n",
    "gauss_kernel = gaussKernel(20,3);\n",
    "\n",
    "targets = [];\n",
    "\n",
    "for sessionNum in range(10):\n",
    "    for trialNum in range(14):\n",
    "        \n",
    "        #trialNum = random.randint(0,7);\n",
    "        \n",
    "        rawSpikes = f[x_ref[trialNum,task,sessionNum]];\n",
    "        \n",
    "        if len(rawSpikes) <= 2:\n",
    "            continue;\n",
    "        else:\n",
    "            rawSpikes_tr = np.transpose(rawSpikes[0:3000,:]);\n",
    "            \n",
    "            #cursorState = f_cursorState[xstate_ref[trialNum, task, sessionNum]];\n",
    "            \n",
    "            targets.append(task);\n",
    "            \n",
    "            #Normalize data along the rows (so that each neuron has a mean-0)\n",
    "            mu_matrix = np.mean(rawSpikes_tr,axis=1)\n",
    "            std_matrix = rawSpikes_tr.std(1)\n",
    "            \n",
    "            #print([np.count_nonzero(std_matrix),np.count_nonzero(mu_matrix)])\n",
    "            #print(std_matrix.squeeze())\n",
    "            \n",
    "            # Making zero entry in std_matrix = 1 (to prevent divide by zero run-time error)\n",
    "        \n",
    "            zero_index = np.where(std_matrix == 0)[0];\n",
    "            for index in range(len(zero_index)):\n",
    "                std_matrix[zero_index[index]] = 1;\n",
    "            \n",
    "            #print([np.count_nonzero(std_matrix),np.count_nonzero(mu_matrix)])\n",
    "                        \n",
    "            t1 = (rawSpikes_tr.transpose()-mu_matrix).transpose();\n",
    "            t2 = (t1.transpose()/std_matrix).transpose();\n",
    "            \n",
    "            rawSpikes_tr = t2;            \n",
    "            \n",
    "            #rawSpikes_tr = gauss_smooth(rawSpikes_tr, gauss_kernel);\n",
    "            \n",
    "            \n",
    "            neuron_tempTensor[:,:,ctr] = rawSpikes_tr;\n",
    "            ctr = ctr + 1;\n",
    "\n",
    "\n",
    "#print(ctr)\n",
    "neuron_tensor = neuron_tempTensor[:,:,0:ctr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import cursor-state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 3000, 55)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index:1 - Number of trials; Index:2 - Number of tasks; Index:3 - Number of sessions\n",
    "xstate_ref = arrays_cursorState['struct_state']\n",
    "\n",
    "cursorState = f_cursorState[xstate_ref[1,task,1]];\n",
    "target_state = np.transpose(cursorState);\n",
    "\n",
    "neuron_tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor decomposition\n",
    "CP approximation to kruskal form and via Jenreich's theorem - identify components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build predictive model\n",
    "from tensorly.regression.kruskal_regression import KruskalRegressor\n",
    "import tensorly.backend as T\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "X = T.tensor(neuron_tensor);\n",
    "factors = parafac(X,rank=3)\n",
    "\n",
    "\n",
    "#plt.plot(trialFactors[:,1])\n",
    "\n",
    "#for comp in factors:\n",
    "#    comp_e = comp.squeeze()\n",
    "#    print(comp_e[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronFactors = factors[0];\n",
    "temporalFactors = factors[1];\n",
    "trialFactors = factors[2];\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(neuronFactors)\n",
    "plt.title('Neuron Factors')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(temporalFactors)\n",
    "plt.title('temporal Factors')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(trialFactors)\n",
    "plt.title('Trial Factors')\n",
    "plt.legend({'1','2','3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 3000, 55)\n",
      "(3000, 96, 55)\n",
      "(35,)\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_tensor = neuron_tensor[:,:,:];\n",
    "print(train_tensor.shape)\n",
    "\n",
    "test_tensor = neuron_tensor[:,:,35:50];\n",
    "test_tensor.shape\n",
    "\n",
    "train_targets = np.array(targets[0:35])\n",
    "test_targets = np.array(targets[35:50])\n",
    "train_targets\n",
    "\n",
    "train_tensor = np.reshape(train_tensor, (train_tensor.shape[1],train_tensor.shape[0], train_tensor.shape[2]))\n",
    "test_tensor = np.reshape(test_tensor, (test_tensor.shape[1],test_tensor.shape[0], test_tensor.shape[2]))\n",
    "\n",
    "print(train_tensor.shape)\n",
    "print(train_targets.shape)\n",
    "\n",
    "print(target_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 96, 55)\n",
      "(3000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorly.regression.kruskal_regression.KruskalRegressor at 0x201de68f278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor regression\n",
    "\n",
    "X = T.tensor(train_tensor);\n",
    "y1 = T.tensor(target_state[:,0]);\n",
    "y2 = T.tensor(target_state[:,1]);\n",
    "\n",
    "print(X.shape)\n",
    "print(y1.shape)\n",
    "rank = 2\n",
    "estimator1 = KruskalRegressor(weight_rank=rank, tol=10e-7, n_iter_max=100, reg_W=1, verbose=0)\n",
    "estimator1.fit(X, y1)\n",
    "estimator2 = KruskalRegressor(weight_rank=rank, tol=10e-7, n_iter_max=100, reg_W=1, verbose=0)\n",
    "estimator2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 =estimator1.kruskal_weight_\n",
    "electro_latent1 = T.to_numpy(res1[1])\n",
    "\n",
    "res2 =estimator2.kruskal_weight_\n",
    "electro_latent2 = T.to_numpy(res2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 55)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = estimator1.weight_tensor_\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(electro_latent1.shape)\n",
    "print(electro_latent2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1, 1,1)\n",
    "ax.scatter(electro_latent[:,0],electro_latent[:,1], np.linspace(0,96),cmap=plt.cm.OrRd)\n",
    "ax.set_axis_off()\n",
    "\n",
    "fig2= plt.figure(2)\n",
    "plt.plot(electro_latent[:,0])\n",
    "plt.plot(electro_latent[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = estimator.predict(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_test)\n",
    "print(test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= estimator.weight_tensor_\n",
    "print(v.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(T.to_numpy(estimator.weight_tensor_), cmap=plt.cm.OrRd, interpolation='nearest')\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Learned regression weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = f[x_ref[6,0,0]][()]\n",
    "d = v[0:3000,:]\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_tensor = np.zeros([96,3000,40]);\n",
    "v = np.ones([96,3000]);\n",
    "v.shape\n",
    "\n",
    "neuron_tensor[:,:,0] = v;\n",
    "neuron_tensor[:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(3,3,3)\n",
    "x = T.tensor(a)\n",
    "print(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Questions:\n",
    "\n",
    "1. Non-negative tensor decomposition using tensorly?\n",
    "2. Different kinds of decomposition - Tucker/CP/non-negative?\n",
    "3. Tensor regression assumes each trial is independent (or each time-point is sampled iid). [NOT TRUE!]\n",
    "4. Tensor based Gaussian processes (for smoothing the spike-bins)?!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
